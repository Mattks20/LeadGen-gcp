# Project Lumina Development Rules

## Core Principles

### 1. Modularity First
- **All targeting logic lives in `config/icp_current.json`**
- Never hardcode industry, pain points, or ICP criteria in Python code
- The engine should work for ANY industry by swapping the JSON config file
- Code should be client-agnostic and reusable

### 2. Multi-Model Consensus Scoring
- **Every lead MUST be scored by at least 2 AI models before approval**
- Primary: Claude 3.5 Sonnet/Opus (Anthropic)
- Secondary: GPT-4o (OpenAI) OR Gemini 2.0 (Google)
- Scoring range: 0-100
- A lead qualifies only if BOTH models score >= 70
- If models disagree by >20 points, flag for manual review

### 3. Authentication & Security
- Use Google Service Account JSON for all Google Workspace API calls
- Store credentials in `credentials/service-account.json` (gitignored)
- Never commit API keys or secrets to version control
- Use environment variables for sensitive configuration

### 4. Google Sheets as Database
- Google Sheets acts as the UI and data layer
- Sheet structure:
  - **Leads**: Company Name, Contact, Email, Phone, Score (Claude), Score (Secondary), Status, Timestamp
  - **Config**: Mirror of ICP parameters for non-technical users
  - **Logs**: Execution history, errors, API usage
- All writes to Sheets must be batched to minimize API calls

### 5. Error Handling & Resilience
- All API calls must have retry logic (exponential backoff)
- Log all errors to Google Sheets "Logs" tab
- Graceful degradation: If one AI model fails, continue with available models
- Rate limiting: Respect API quotas for all services

### 6. Cost Optimization
- Use Gemini 2.0 Flash for initial discovery (cheapest)
- Use Claude Sonnet for primary scoring (best balance)
- Use Claude Opus only for high-value leads or edge cases
- Cache API responses where applicable
- Batch operations to minimize API calls

### 7. Code Organization

```
/config/
  icp_current.json          # The modular brain - all targeting parameters

/core/
  discovery.py              # Gemini-powered lead discovery
  scoring.py                # Multi-model consensus scoring engine
  workspace.py              # Google Sheets/Workspace integration
  models.py                 # Pydantic models for type safety

/credentials/
  service-account.json      # Google Service Account (GITIGNORED)

/plans/
  implementation.md         # Step-by-step implementation plan

/utils/
  logger.py                 # Centralized logging
  retry.py                  # Retry decorators for API calls
```

### 8. Development Workflow
- Use async/await for all I/O operations
- Type hints on all functions
- Pydantic models for data validation
- Unit tests for scoring logic
- Integration tests for Sheets operations

### 9. Configuration Schema (icp_current.json)

```json
{
  "industry": "string",
  "company_size": "string",
  "pain_points": ["array"],
  "decision_makers": ["array"],
  "geographic_focus": ["array"],
  "budget_range": "string",
  "tech_stack": ["array"],
  "buying_signals": ["array"]
}
```

### 10. Scoring Logic Rules
- Base score from company fit (0-40 points)
- Pain point alignment (0-30 points)
- Buying signals detected (0-20 points)
- Contact quality (0-10 points)
- Consensus requirement: Both models within 15 points
- Auto-reject if either model scores < 50

## Implementation Checklist
- [ ] Google Sheets authentication working
- [ ] ICP config loading from JSON
- [ ] Gemini discovery pipeline
- [ ] Claude scoring integration
- [ ] Secondary model scoring (GPT-4o or Gemini)
- [ ] Consensus logic implementation
- [ ] Sheets write operations (batched)
- [ ] Error logging to Sheets
- [ ] Rate limiting & retry logic
- [ ] End-to-end integration test

## Commands for Quick Reference
```bash
# Install dependencies
pip install -r requirements.txt

# Run discovery pipeline
python -m core.discovery

# Run scoring on existing leads
python -m core.scoring

# Test Sheets connection
python -m core.workspace --test
```
